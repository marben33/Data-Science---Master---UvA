{"metadata":{"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"},"kernelspec":{"name":"ir","display_name":"R","language":"R"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Vlogger Big-Five Competition\n## Competition I - Round II\n### University of Amsterdam\n### Behavioral Data Science\n### Group 9\n#### Romy Leferink, Bence Marosi, Sophia Lorenz\n#### September 18, 2023\n---\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## The YouTube Personality Dataset\n\nIn the following, we analyzed data of YouTube vlogger. For this a dataset called \"YouTube personality dataset\" was used which contains data of 404 YouTube vloggers. All vloggers in the dataset explicitly talked about a variety of topics including personal issues, politics, movies, books, etc and the language is diverse. \nThe dataset consists of a collection of behavorial features, speech transcriptions, and personality impression scores of the YouTube vloggers. \n\n---","metadata":{}},{"cell_type":"markdown","source":"## 0 Directories\n\n#### 0.0 Load the libraries required to conduct the data analysis","metadata":{}},{"cell_type":"code","source":"library(tidyverse) \nlibrary(tidytext)","metadata":{"_uuid":"047afe52-49c0-4445-bc38-8ce6b6825e9d","_cell_guid":"39fc8038-1e29-4bb3-8486-160aa629127b","collapsed":false,"_execution_state":"idle","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-18T09:17:40.126326Z","iopub.execute_input":"2023-09-18T09:17:40.127762Z","iopub.status.idle":"2023-09-18T09:17:40.141853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 0.1 Load all files under the \"../input/\" directory","metadata":{}},{"cell_type":"code","source":"list.files(path <- \"../input\")\n\nmaster_dir <- file.path(list.files('../input', full.names=TRUE), 'youtube-personality')\ndirectory_content <- list.files(master_dir, full.names = TRUE)\nprint(directory_content)","metadata":{"_uuid":"5a7e0e4d-bd75-4313-ad70-0df228feef48","_cell_guid":"60fffa58-51df-4b85-8405-7208ac965554","execution":{"iopub.status.busy":"2023-09-18T09:17:40.143973Z","iopub.execute_input":"2023-09-18T09:17:40.145046Z","iopub.status.idle":"2023-09-18T09:17:40.173352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 1 Importing Data\n\nWe'll import\n\n- Audio-visual information\n- Gender\n- Personality scores\n- Transcripts\n\n\nThere are three `.csv` files in the directory structure (see line \\[3\\], \\[4\\], and \\[5\\] in the output above).","metadata":{}},{"cell_type":"markdown","source":"#### 1.1 Importing audiovisual information\n\nThe file path containing the audiovisual`.csv` file is stored in a variable which is used to read in the audio-visual data. \n\n*Note:* For all `.csv` files the `read_delim()` function was used instead of the`read_csv()` function because the data are not comma separated but delimited with a space.","metadata":{}},{"cell_type":"code","source":"audiovisual_file <- directory_content[3]\naudiovisual_df <- read.table(audiovisual_file, head=TRUE)\n\naudiovisual_df %>% \n    names()\n\naudiovisual_df %>% \n    head()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:40.175306Z","iopub.execute_input":"2023-09-18T09:17:40.176436Z","iopub.status.idle":"2023-09-18T09:17:40.227548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1.2 Importing gender information\nThe file path containing the gender`.csv` file is stored in a variable which is used to read in the gender data. This file did not have any column names which were added. \n","metadata":{}},{"cell_type":"code","source":"gender_file <- directory_content[4]\ngender_df <- read.delim(gender_file, head=FALSE, sep=\" \", skip = 2)\n\n# Adding column names\nnames(gender_df) <- c('vlogId', 'gender')\n\ngender_df %>% \n    head()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:40.230452Z","iopub.execute_input":"2023-09-18T09:17:40.231605Z","iopub.status.idle":"2023-09-18T09:17:40.258195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1.3 Importing personality information","metadata":{}},{"cell_type":"code","source":"personality_file <- directory_content[5]\npersonality_df <- read_delim(personality_file, delim=\" \", show_col_types=FALSE)\n\npersonality_df %>% \n    head()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:40.260259Z","iopub.execute_input":"2023-09-18T09:17:40.261308Z","iopub.status.idle":"2023-09-18T09:17:40.303580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1.4 Importing transcripts\nThere is a \"transcript\" subfolder (see line \\[2\\] in the output above) in which the actual video transcripts are stored in `.txt` files. A path was created to the transcripts directory. A selection of the transcripts is listed below:","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"path_to_transcripts = directory_content[2] \ntranscript_files = list.files(path_to_transcripts, full.names = TRUE) \n\ntranscript_files %>% \n    head()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:40.305639Z","iopub.execute_input":"2023-09-18T09:17:40.306730Z","iopub.status.idle":"2023-09-18T09:17:40.327517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 2 Preparing Data for the Analysis\n\n#### 2.1 Extracting vlogger ID from vlogger names\nTo protect the privacy of the vloggers, their names were removed before conducting the analysis. The vlogger ID needed to be encoded as we need this for joining information from the different dataframes. Furthermore, we removed the file extension \".txt\".","metadata":{"_uuid":"4e3cb8fd-83db-4698-a565-2115a202fe9b","_cell_guid":"c87a60dd-6c43-4ed6-a35f-45d4efc47db6","trusted":true}},{"cell_type":"code","source":"vlogId = basename(transcript_files)\nvlogId = str_replace(vlogId, pattern = \".txt$\", replacement = \"\")\n\nvlogId %>% \n    head()","metadata":{"_uuid":"9a179032-bde8-462a-b223-89a45b1338d9","_cell_guid":"93382a21-dd15-4747-94b4-203131cbe705","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-18T09:17:40.329582Z","iopub.execute_input":"2023-09-18T09:17:40.330648Z","iopub.status.idle":"2023-09-18T09:17:40.346295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.2 Transcript features\nTo include features extracted from the transcript texts, the text from files was stored in a dataframe.","metadata":{"_uuid":"a48356cc-bb9c-4edd-9cca-0082f5dfcdaf","_cell_guid":"e5bd1c34-e28f-4b02-a1a5-c49037d8e40d","trusted":true}},{"cell_type":"code","source":"transcripts_df <- tibble(\n    \n    # vlogId connects each transcripts to a vlogger\n    vlogId = vlogId,\n    \n    # Read the transcript text from all files and store as string\n    TEXT = map_chr(transcript_files, ~ paste(readLines(.x), collapse = \"\\\\n\")), \n    \n    # `filename` contains specific video transcript\n    filename = transcript_files\n)\n\ntranscripts_df %>% \n    head(2)","metadata":{"_uuid":"bb66ae39-9ef8-46fb-8971-082dc333bdb8","_cell_guid":"1553130b-5066-4d9b-8219-9c1ca9b3ba1a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-18T09:17:40.348399Z","iopub.execute_input":"2023-09-18T09:17:40.349492Z","iopub.status.idle":"2023-09-18T09:17:40.985284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.3 Merging `gender` and `personality` dataframes\nThe dataframes `gender` and `personality` were merged which is necessary for the analysis. ","metadata":{"_uuid":"4093194b-da93-4b07-996f-82c1fe810418","_cell_guid":"252e73f9-ed0f-4161-a6e8-f287e6dfaddc","trusted":true}},{"cell_type":"code","source":"vlogger_df <- left_join(gender_df, personality_df, by='vlogId')\n\nvlogger_df %>% \n    head() # VLOG8 has missing personality scores: those should be predicted!","metadata":{"_uuid":"58eb0582-3c68-458e-a807-187ef63fd52a","_cell_guid":"15d7bd85-f197-4803-8daa-6193f7929978","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-18T09:17:40.987437Z","iopub.execute_input":"2023-09-18T09:17:40.988485Z","iopub.status.idle":"2023-09-18T09:17:41.013948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___","metadata":{}},{"cell_type":"markdown","source":"## 3 Feature Extraction from Transcripts\n\n#### 3.1 Transcripts tokenized by words\n\nBy breaking down the text into individual words (tokens) sentiments can be assigned to each token.","metadata":{"_uuid":"cda7cf6b-3680-4451-b1c5-6e276d2d5430","_cell_guid":"b3b16406-5f3b-45c5-b1a9-9d2f98d66210","trusted":true}},{"cell_type":"code","source":"transcripts_tokenized <- \n    transcripts_df %>%\n    unnest_tokens(token, TEXT, token = 'words')","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:41.015964Z","iopub.execute_input":"2023-09-18T09:17:41.017081Z","iopub.status.idle":"2023-09-18T09:17:41.154060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.2 Deleting stopwords from the transcript words\n\nBy deleting stopwords from the transcript words (`transcripts_tokenized`) we avoid having common words interfer with our data analysis. For example, words like \"the\", \"a\", ect. are commonly used in language but do not necessary add to the sentiment analysis. Thus, it makes sense to exclude those stopwords from the sentiment analysis because first, the predictions become more accurate and second, the data becomes cleaner.","metadata":{}},{"cell_type":"code","source":"stopwords <- get_stopwords()\n\ntranscripts_tokenized <-\n    transcripts_tokenized %>%\n    anti_join(stopwords, by = c(token = \"word\"))","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:41.156299Z","iopub.execute_input":"2023-09-18T09:17:41.157392Z","iopub.status.idle":"2023-09-18T09:17:41.207915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#### 3.3 Retrieving lexica\nHelper function in order to retrieve different lexica from the `textdata` package. The lexica of interest contain emotion data and are particularly used for sentiment analysis. ","metadata":{}},{"cell_type":"code","source":"get_lexicon = function(lexicon_name = names(textdata:::download_functions)) {\n    lexicon_name = match.arg(lexicon_name)\n    textdata:::download_functions[[lexicon_name]]('.')\n    rds_filename = paste0(lexicon_name,'.rds')\n    textdata:::process_functions[[lexicon_name]]('.',rds_filename)\n    readr::read_rds(rds_filename)\n}","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:41.210123Z","iopub.execute_input":"2023-09-18T09:17:41.211201Z","iopub.status.idle":"2023-09-18T09:17:41.221078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.4 \"nrc\" lexicon\n\nFor the following sentiment analysis the \"nrc\" lexicon was used. This lexicon is based on Plutchick's wheel of emotion. Psychologist Robert Plutchik proposed this model which consists of 8 base emotions: \n- joy\n- trust\n- fear\n- surprise\n- sadness\n- anticipation\n- anger\n- disgust\nEach base emotion has a polar opposite. Thus, Plutchik's model also contains a positive valence and a negative valence.\n\nThe nrc lexicon assigns a sentiment, that is, a positive or negative valence and / or a base emotion typically conveyed by a word to each word in the transcripts_tokenized dataframe. Note that the \"nrc\" lexicon is incomplete so that not each word in the `transcripts_tokenized` dataframe gets an emotion assigned. Those tokens without a sentiment were dropped because they do not add anything to the analysis.","metadata":{}},{"cell_type":"code","source":"# loading \"nrc\" lexicon\nnrc <- get_lexicon('nrc')\n\n# left joining the \"nrc\" lexicon and tokenized transcripts\ntranscripts_token_labeled <-\n    left_join(transcripts_tokenized, nrc, by = c(token = 'word'), relationship='many-to-many')\n\n# dropping rows with no sentiment\ntranscript_features_df <-\n    transcripts_token_labeled %>%\n    filter(!is.na(sentiment))\n\ntranscript_features_df %>% \n    head()","metadata":{"_uuid":"1540d512-f479-4475-aaa9-45c3acae5178","_cell_guid":"f80d89e3-c233-4a5d-ba0c-7f1ca9fb1b04","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-18T09:17:41.223322Z","iopub.execute_input":"2023-09-18T09:17:41.224421Z","iopub.status.idle":"2023-09-18T09:17:41.607546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.5 Merging sentimented transcripts with `vlogger_df` dataframe\nThe dataframes`vlogger_df` and`transcript_features_df` were merged into `vlogger_transcript_df`. Furthermore, we deleted the `filename` column because it is not needed for the rest of the analysis.","metadata":{"_uuid":"f8ba05cf-8815-4bb2-b49b-9eccdd6c2762","_cell_guid":"db396ed9-f94c-48f9-b2ac-1be5792d2a89","trusted":true}},{"cell_type":"code","source":"# merging `vlogger_df` with `transcript_features_df` into `vlogger_transcript_df`\nvlogger_transcript_df <-\n    vlogger_df %>%\n    left_join(transcript_features_df, by = \"vlogId\")\n\n# deleting \"filename\" column\nvlogger_transcript_df <-\n    vlogger_transcript_df %>%\n    select(-filename)\n\nvlogger_transcript_df %>% \n    head()","metadata":{"_uuid":"471f379b-78cb-40bc-a81a-4e74969ec4d6","_cell_guid":"f8532d3c-a6d0-430b-82bc-496bc93587e6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-18T09:17:41.609369Z","iopub.execute_input":"2023-09-18T09:17:41.610309Z","iopub.status.idle":"2023-09-18T09:17:41.641410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.6 Counting sentiment scores\n\nThe sentiment scores were counted for each vlogger as part of the sentiment analysis.","metadata":{}},{"cell_type":"code","source":"vlogger_sentiment_scores <-\n    vlogger_transcript_df  %>%\n    count(`vlogId`, sentiment)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:41.643291Z","iopub.execute_input":"2023-09-18T09:17:41.644263Z","iopub.status.idle":"2023-09-18T09:17:41.692047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.7 Wide dataframe for sentiment \n\nThe long format of the `vlogger_sentiment_scores` dataframe is transformed into a wide dataframe such that each sentiment has a separate column.","metadata":{}},{"cell_type":"code","source":"vlogger_sentiment_wide <- \n    vlogger_sentiment_scores %>%\n    pivot_wider(id_cols = 'vlogId', names_from=sentiment, values_from=n, values_fill = 0)\n\nvlogger_sentiment_wide %>% \n    head()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:41.694052Z","iopub.execute_input":"2023-09-18T09:17:41.695104Z","iopub.status.idle":"2023-09-18T09:17:41.737980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.8 Merging sentiment data with vlogger data\n\nThe sentiment data of the `vlogger_sentiment_wide` dataframe was merged with the vlogger data of `vlogger_transcript_df`. The columns `token` and `sentiment` were dropped as they won't be needed for the rest of the analysis. This ensures a cleaner picture of the data.","metadata":{}},{"cell_type":"code","source":"vlogger_features =\n    inner_join(vlogger_transcript_df, vlogger_sentiment_wide, by = \"vlogId\") %>%\n    select(-c(token, sentiment)) %>%\n    distinct()\n\nvlogger_features %>% \n    head()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:41.740088Z","iopub.execute_input":"2023-09-18T09:17:41.741186Z","iopub.status.idle":"2023-09-18T09:17:41.786559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.9 Splitting into training data and test data\n\nThe `vlogger_features` dataframe is split into training data and test data. Splitting the data in training and test data allows to train the model based on the training data which contains labels. Then, the model is run on the testing data to make predictions about the new, unseen, testing data. \n\nThe training data contains all the vlogger data; the sentiment of each vlogger's transcript (`vlogger_sentiment_wide`; predictor variable) as well as the personality score based on the big5 of the personality dataset (`personality_df`; outcome variable).\nIn contrast, the test data only contains each vlogger's transcript (`vlogger_sentiment_wide`; predictor variable) but not the personality score. Test data are those `vlogId`'s where the big5 personality scores of the dataframe `personality_df` are missing (`NA`).\n","metadata":{}},{"cell_type":"code","source":"# training data\nvlogger_features_training <-\n    vlogger_features %>%\n    drop_na(c(Extr, Agr, Cons, Emot, Open))\n\nvlogger_features_training %>% \n    head()\n\n# test data\nvlogger_features_test <-\n    vlogger_features %>%\n    anti_join(vlogger_features_training, by = \"vlogId\")\n\nvlogger_features_test %>% \n    head()\n\n# number of vloggers for each dataset (combined, training, test)\nnrow(vlogger_features)\nnrow(vlogger_features_training)\nnrow(vlogger_features_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:41.788691Z","iopub.execute_input":"2023-09-18T09:17:41.789777Z","iopub.status.idle":"2023-09-18T09:17:41.859394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.10 Merging audiovisual data with vlogger data\n\nThe audiovisual data of the `audio_visual` dataframe is merged with the vlogger data of `vlogger_df` into `vlogger_audiovisual`. This way we do not only base our predictions of vlogger's personalities based on what they are saying in their vloggs (transcript data) but also based on audiovisual features. We expect more accurate predictions of our models if we include more data.","metadata":{}},{"cell_type":"code","source":"vlogger_audiovisual =\n    inner_join(vlogger_df, audiovisual_df, by = \"vlogId\") %>%\n    distinct()\n\nvlogger_audiovisual %>% \n    head()\n\nvlogger_audiovisual %>% \n    names()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:41.861649Z","iopub.execute_input":"2023-09-18T09:17:41.862709Z","iopub.status.idle":"2023-09-18T09:17:41.914825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.11 Splitting into training data and test data\n\nThe `vlogger_audiovisual` dataframe is split into training data and test data for the same reason as previously explained.\n\nThe training data contains all the vlogger data; the audiovisual data (`audiovisual_df`; predictor variable) of each vlogger and the personality score based on the big5 of the personality dataset (`personality_df`; outcome variable) as well as gender data (`gender_df`).\nIn contrast, the test data only contains each vlogger's audiovisual data (`audiovisual_df`; predictor variable) but not the personality score. Test data are those `vlogId`'s where the big5 personality scores of the dataframe `personality_df` are missing (`NA`).","metadata":{}},{"cell_type":"code","source":"# training data\nvlogger_audiovisual_training <-\n    vlogger_audiovisual %>%\n    drop_na(c(Extr, Agr, Cons, Emot, Open))\n\nvlogger_audiovisual_training %>% \n    head()\n\n# test data\nvlogger_audiovisual_test <-\n    vlogger_audiovisual %>%\n    anti_join(vlogger_audiovisual_training, by = \"vlogId\")\n\nvlogger_audiovisual_test %>% \n    head()\n\n\n# number of vloggers for each dataset (combined, training, test)\nnrow(vlogger_audiovisual)\nnrow(vlogger_audiovisual_training)\nnrow(vlogger_audiovisual_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:41.916890Z","iopub.execute_input":"2023-09-18T09:17:41.918011Z","iopub.status.idle":"2023-09-18T09:17:42.001176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.12 Merging audiovisual data with transcrip features data \n\nThe `audiovisual_df` dataframe is merged with the `vlogger_features` dataframe, to get a dataframe with all text- and audiovisual features.","metadata":{}},{"cell_type":"code","source":"features_audiovisual_df =\n    inner_join(audiovisual_df, vlogger_features, by = \"vlogId\") %>%\n    distinct()\n\nfeatures_audiovisual_df %>% \n    head()\n\nfeatures_audiovisual_df %>% \n    names()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.003205Z","iopub.execute_input":"2023-09-18T09:17:42.004246Z","iopub.status.idle":"2023-09-18T09:17:42.053054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.13 Splitting into training data and test data\n\nLike the previous dataframes, the `features_audiovisual_df` dataframe is then split into test and training data. \n\nThe training data contains all the vlogger data; the audiovisual data (`audiovisual_df`; predictor variable) of each vlogger, the data of the transcripted features (`vlogger_features`; predictor variable) and the personality score based on the big5 of the personality dataset (`personality_df`; outcome variable),  as well as gender data (`gender_df`).\nIn contrast, the test data only contains each vlogger's audiovisual data (`audiovisual_df`; predictor variable) and the data of the transcripted features (`vlogger_features`; predictor variable) but not the personality score. Test data are those `vlogId`'s where the big5 personality scores of the dataframe `personality_df` are missing (`NA`).","metadata":{}},{"cell_type":"code","source":"# training data\nfeatures_audiovisual_df_train <-\n    features_audiovisual_df %>%\n    drop_na(c(Extr, Agr, Cons, Emot, Open))\n\nfeatures_audiovisual_df_train %>% \n    head()\n\n# test data\nfeatures_audiovisual_df_test <-\n    features_audiovisual_df %>%\n    anti_join(features_audiovisual_df_train, by = \"vlogId\")\n\nfeatures_audiovisual_df_test %>% \n    head()\n\n\n# number of vloggers for each dataset (combined, training, test)\nnrow(features_audiovisual_df)\nnrow(features_audiovisual_df_test)\nnrow(features_audiovisual_df_train)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.055139Z","iopub.execute_input":"2023-09-18T09:17:42.056278Z","iopub.status.idle":"2023-09-18T09:17:42.152903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___","metadata":{}},{"cell_type":"markdown","source":"## 4 Predictive Linear Models\n\nModels are trained on the training data in order to predict the Big5 personality trait of each vlogger in the dataset. Multiple regression was applied on the data with five personality traits (outcome variable) with eight emotions and two valences (predictors). Different multiple linear regression models with differing structures were used for the training.\n\n#### 4.1 Linear model 1\nFirst, we specified a full linear model containing all 10 predictors to investigate which predictors have significant effects on which outcomes (Model 1).  ","metadata":{"_uuid":"54aafd4b-9834-4086-8030-702069f39518","_cell_guid":"ba49ed13-9045-4b21-9f2e-09b58bc02b41","trusted":true}},{"cell_type":"code","source":"fit_mlm_01 <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ anger + anticipation + \n                 disgust + fear + joy + negative + positive + sadness + \n                 surprise + trust, data = features_audiovisual_df_train)\n\nsummary(fit_mlm_01)","metadata":{"_uuid":"972d1589-1ba3-49b3-bae8-9e09c7666a21","_cell_guid":"8a713b08-df61-4c46-b392-1084c9f357b4","execution":{"iopub.status.busy":"2023-09-18T09:17:42.156194Z","iopub.execute_input":"2023-09-18T09:17:42.157564Z","iopub.status.idle":"2023-09-18T09:17:42.188249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.2 Linear model 2\nSecond, we specified a linear model with all 10 predictors and an interaction of`surprise`  and`positive` (Model 2). We assumed an interaction effect between`surprise`  and`positive`  as surprise can be both - positive and negative.`surprise`  has to be positive to have a ‘positive’ influence \non the outcome (e.g. more positively valenced suprise words could indicate higher extraversion).","metadata":{}},{"cell_type":"code","source":"fit_mlm_02 <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ anger + anticipation + \n                 disgust + fear + joy + negative + positive + sadness + trust + \n                 surprise*positive, data = features_audiovisual_df_train)\n\nsummary(fit_mlm_02)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.191419Z","iopub.execute_input":"2023-09-18T09:17:42.192668Z","iopub.status.idle":"2023-09-18T09:17:42.230541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.3 Linear model 3\n\nThird, we specified a linear model that contains interaction effects between each emotion and its corresponding valence according to Plutchick's wheel of emotion (Model 3). ","metadata":{}},{"cell_type":"code","source":"fit_mlm_03 <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ anger*negative + \n                 anticipation*positive + disgust*negative + fear*negative + \n                 joy*positive + sadness*negative + trust*positive +\n                 surprise*positive + disgust*negative, data = features_audiovisual_df_train)\n\nsummary(fit_mlm_03)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.233757Z","iopub.execute_input":"2023-09-18T09:17:42.234946Z","iopub.status.idle":"2023-09-18T09:17:42.275565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.4 Linear model 4\n\nFourth, we specified a linear model (Model 4) which only contains the predictors that were shown to be significant in the full model (Model 1). ","metadata":{}},{"cell_type":"code","source":"fit_mlm_04 <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ anger + disgust \n                 + fear + positive + surprise, data = features_audiovisual_df_train)\n\nsummary(fit_mlm_04)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.278354Z","iopub.execute_input":"2023-09-18T09:17:42.279883Z","iopub.status.idle":"2023-09-18T09:17:42.312799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.5 Linear model 5 \n\nMaharani and Effendy (2022) investigated big five personality prediction using machine learning methods. They tried to predict the personality traits of social media users by investigating their tweets using the NRC emotion lexicon. They found that Conscientiousness, Extraversion and Agreeableness were significantly correlated with anticipantion, joy, surprise and trust. Additionally, they found significant correlations between Openness and Neuroticisim and sadness, disgust, anger and fear. Based on these results, we formed the following models (Model 5 and Model 6). \n\nThe fifth model is a linear model which contains `Conscientiousnes`,`Extraversion` and `Agreeablenes` as outcome variables and `anticipation`, `joy`, `surprise`, and `trust` as predictors (Model 5).  ","metadata":{}},{"cell_type":"code","source":"fit_mlm_05 <- lm(cbind(Extr, Agr, Cons)  ~ anticipation + joy + surprise + trust, \n                 data = features_audiovisual_df_train)\n\nsummary(fit_mlm_05)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.315617Z","iopub.execute_input":"2023-09-18T09:17:42.317336Z","iopub.status.idle":"2023-09-18T09:17:42.345046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.6 Linear model 6\n\nAlso based on the study by Maharani and Effendy (2022), we formed a linear model containing `Opennes` and `Neuroticism` as outcome variables and `sadness`, `disgust`, `anger` and `fear` as predictors (Model 6). ","metadata":{}},{"cell_type":"code","source":"fit_mlm_06 <- lm(cbind(Emot, Open) ~ anger + disgust + fear + sadness,\n                 data = features_audiovisual_df_train)\n\nsummary(fit_mlm_06)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.347959Z","iopub.execute_input":"2023-09-18T09:17:42.349491Z","iopub.status.idle":"2023-09-18T09:17:42.374883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.7 Linear model 7\n\nSimilarly, Farnadi et al. (2014) studied the relationship between emotions expressed in Facebook status updates and user’s personality according to the Big Five model. These researchers deployed the NRC emotion lexicon as well. The results showed that Openness and Extraversion were significantly correlated with all emotions and valences from the NRC lexicon. These regressions were already included in the full model (Model 1, `fit_mlm_0`). For the other personality traits, Farnadi et al. (2014) found that Conscientiousness was correlated with all emotions/valences except negativity, anger and sadness; that agreeableness was correlated with all emotions/valences  except sadness; and that neuroticism was correlated with all emotions/valences except positivity, anticipation and trust. Based on these results, the following three models (Model 7, Model 8, Model 9) were formed.  \n\nThe seventh model is a linear model for the outcome variable `Conscientiousness` with `anticipation`, `disgust`, `fear`, `joy`, `positive`, `surprise`, and `trust` as predictors (Model 7). ","metadata":{}},{"cell_type":"code","source":"fit_mlm_07 <- lm(Cons ~ anticipation + disgust + fear + joy + positive + \n                 surprise + trust, data = features_audiovisual_df_train)\n\nsummary(fit_mlm_07)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.377063Z","iopub.execute_input":"2023-09-18T09:17:42.378187Z","iopub.status.idle":"2023-09-18T09:17:42.395650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.8 Linear model 8\n\nAlso based on the study by Farnadi et al. (2014), we specified a model with outcome variable `Agreeableness` and `anger`, `anticipation`,`disgust`,`fear`, `joy`, `negative`, `positive`, `surprise`, and `trust` as predictors (Model 8). ","metadata":{}},{"cell_type":"code","source":"fit_mlm_08 <- lm(Agr ~ anger + anticipation + disgust + fear + joy + negative + \n                 positive + surprise + trust, data = features_audiovisual_df_train)\n\nsummary(fit_mlm_08)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.397816Z","iopub.execute_input":"2023-09-18T09:17:42.399018Z","iopub.status.idle":"2023-09-18T09:17:42.417116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.9 Linear model 9\n\nAlso based on the study by Farnadi et al. (2014), we formed a model for the outcome variables `Neuroticism` and `Emotional Stability` with `anger`,`disgust`, `fear`,`joy`, `negative`, `sadness`, and `surprise` as predictors (Model 9). ","metadata":{}},{"cell_type":"code","source":"fit_mlm_09 <- lm(Emot ~ anger + disgust + fear + joy + negative +  \n                 sadness + surprise, data = features_audiovisual_df_train)\n\nsummary(fit_mlm_09)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.419298Z","iopub.execute_input":"2023-09-18T09:17:42.420487Z","iopub.status.idle":"2023-09-18T09:17:42.439275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.10 Linear model 10\n\nBiel and Gatica-Perez (2013) investigated the relationship between several audio and visual cues and Big Five personality traits. They found that energy (audio), speaking time (audio) and the length of looking segments (visual) are significantly correlated with the Big Five personality traits. Based on these results, we formed the following model (Model 10).  \n\nThe tenth model is a linear model containing all five personaltiy traits as outcomes and `mean.energy`,`time.speaking` and `avg.len.seg` as predictors. ","metadata":{}},{"cell_type":"code","source":"fit_mlm_10 <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ mean.energy + time.speaking \n                 + avg.len.seg, data = features_audiovisual_df_train)\n\nsummary(fit_mlm_10)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.441544Z","iopub.execute_input":"2023-09-18T09:17:42.442675Z","iopub.status.idle":"2023-09-18T09:17:42.469930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___","metadata":{}},{"cell_type":"markdown","source":"#### 4.11 linear model 11\n\nLastly, we made a model (Model 11) with the text features from Model 3 – as that model had the lowest RMSE of the models containing all outcomes (see below) – combined with the audiovisual features from Model 10. ","metadata":{}},{"cell_type":"code","source":"fit_mlm_11 <- lm(cbind(Extr, Agr, Cons, Emot, Open) ~ anger*negative + \n                 anticipation*positive + disgust*negative + fear*negative + \n                 joy*positive + sadness*negative + trust*positive +\n                 surprise*positive + disgust*negative + \n                 mean.energy + time.speaking + avg.len.seg, data = features_audiovisual_df_train)\n\nsummary(fit_mlm_11)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.472151Z","iopub.execute_input":"2023-09-18T09:17:42.473325Z","iopub.status.idle":"2023-09-18T09:17:42.512715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5 Predictions \n\n#### 5.1 Predictions on training data set\n\nThe predictions for the training data based on each of our proposed linear models can be found below. Those predictions are needed in order to evaluate each model (i.e., calculate the RMSE; see below).","metadata":{}},{"cell_type":"code","source":"pred_mlm_01_train <-\n    predict(fit_mlm_01)\n\npred_mlm_01_train %>% \n    head()\n\n\npred_mlm_02_train <-\n    predict(fit_mlm_02)\n\npred_mlm_02_train %>% \n    head()\n\n\npred_mlm_03_train <-\n    predict(fit_mlm_03)\n\npred_mlm_03_train %>% \n    head()\n\n\npred_mlm_04_train <-\n    predict(fit_mlm_04)\n\npred_mlm_04_train %>% \n    head()\n\n\npred_mlm_05_train <-\n    predict(fit_mlm_05)\n\npred_mlm_05_train %>% \n    head()\n\n\npred_mlm_06_train <-\n    predict(fit_mlm_06)\n\npred_mlm_06_train %>% \n    head()\n\n\npred_mlm_07_train <-\n    predict(fit_mlm_07)\n\npred_mlm_07_train %>% \n    as.matrix() %>% \n    head()\n\n\npred_mlm_08_train <-\n    predict(fit_mlm_08)\n\npred_mlm_08_train %>% \n    as.matrix() %>% \n    head()\n\n\npred_mlm_09_train <-\n    predict(fit_mlm_09)\n\npred_mlm_09_train %>% \n    as.matrix() %>% \n    head()\n\n\npred_mlm_10_train <-\n    predict(fit_mlm_10)\n\npred_mlm_10_train %>% \n    as.matrix() %>% \n    head()\n\n\npred_mlm_11_train <-\n    predict(fit_mlm_11)\n\npred_mlm_11_train %>% \n    as.matrix() %>% \n    head()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.515623Z","iopub.execute_input":"2023-09-18T09:17:42.517141Z","iopub.status.idle":"2023-09-18T09:17:42.686733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.2 Predictions on test data set\n\nNow the predictions for test data are computed based on each of the eleven linear models. That is what we are actually interested in: we want to predict the (yet unknown) personality of vloggers based on our models. ","metadata":{"_uuid":"04dc5694-5fba-4712-b6a0-5e8ea30ded86","_cell_guid":"d2def0aa-2cf4-47cf-b2f5-31477c6bffda","trusted":true}},{"cell_type":"code","source":"pred_mlm_01_test <-\n    predict(fit_mlm_01, newdata = features_audiovisual_df_test)\n\npred_mlm_01_test %>% \n    head()\n\n\npred_mlm_02_test <-\n    predict(fit_mlm_02, newdata = features_audiovisual_df_test)\n\npred_mlm_02_test %>% \n    head()\n\n\npred_mlm_03_test <-\n    predict(fit_mlm_03, newdata = features_audiovisual_df_test)\n\npred_mlm_03_test %>% \n    head()\n\n\npred_mlm_04_test <-\n    predict(fit_mlm_04, newdata = features_audiovisual_df_test)\n\npred_mlm_04_test %>% \n    head()\n\n\npred_mlm_05_test <-\n    predict(fit_mlm_05, newdata = features_audiovisual_df_test)\n\npred_mlm_05_test %>% \n    head()\n\n\npred_mlm_06_test <-\n    predict(fit_mlm_06, newdata = features_audiovisual_df_test)\n\npred_mlm_06_test %>% \n    head()\n\n\npred_mlm_07_test <-\n    predict(fit_mlm_07, newdata = features_audiovisual_df_test)\n\npred_mlm_07_test %>% \n    as.matrix() %>% \n    head()\n\n\npred_mlm_08_test <-\n    predict(fit_mlm_08, newdata = features_audiovisual_df_test)\n\npred_mlm_08_test %>% \n    as.matrix() %>% \n    head()\n\n\npred_mlm_09_test <-\n    predict(fit_mlm_09, newdata = features_audiovisual_df_test)\n\npred_mlm_09_test %>% \n    as.matrix() %>% \n    head()\n\n\npred_mlm_10_test <-\n    predict(fit_mlm_10, newdata = features_audiovisual_df_test)\n\npred_mlm_10_test %>% \n    as.matrix() %>% \n    head()\n\n\npred_mlm_11_test <-\n    predict(fit_mlm_11, newdata = features_audiovisual_df_test)\n\npred_mlm_11_test %>% \n    as.matrix() %>% \n    head()","metadata":{"_uuid":"9263474a-b2a7-4073-88e4-57af25295b0f","_cell_guid":"9453537e-1d01-45a9-bfb7-b91b891e7b1e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-18T09:17:42.689981Z","iopub.execute_input":"2023-09-18T09:17:42.691188Z","iopub.status.idle":"2023-09-18T09:17:42.836022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 6 Evaluation of Predictions: RMSE Calculations\n\nAs part of the competition, the previously calculated predictions on training data are evaluated by computing the Root Means Square Error (RMSE). The RMSE is one way to assess how well a regression model fits a dataset and a model fit measure that measures the average difference between a model's predicted values and its actual values in the dataset.\n\n**Root Means Square Error**:\n    - $\\displaystyle{RMSE =\\sqrt{{1 \\over 5n} \\sum_{k \\in \\{cEXT, \\ldots, cOPN\\}} \\sum_{i=1}^n (y_{ik} - \\hat y_{ik})^2}}$\n    - Here \n        - $y_{ik}$ is the observed value for vlogger $i$ \n        - $\\hat y_{ik}$ is our prediction for vlogger $i$\n        \nThe lower the RMSE value, the better the given model is at predicting the values of the dataset.","metadata":{}},{"cell_type":"markdown","source":"#### 6.1 RMSE function\nA helper `rmse`() function was created based on the RMSE formula provided above. For the sake of convenience this function was created in order to avoid repeating code as we need to calculate the RMSE for each model. The function takes two arguments:\n- the observed values of each model \n- predicted values of each model\n\nWith those two inputs the RMSE can be calculated. ","metadata":{}},{"cell_type":"code","source":"n <- nrow(vlogger_features_training)\n\nrmse <- function(observed, predicted) {\n  rmse_score = sqrt(1/(5*n) * sum((observed-predicted)^2))\n  return(rmse_score)\n}","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:42.838126Z","iopub.execute_input":"2023-09-18T09:17:42.839219Z","iopub.status.idle":"2023-09-18T09:17:42.850643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In order to calculate the RMSE we need to retrieve the observed values on personality traits.","metadata":{}},{"cell_type":"code","source":"observed_train <-\n    features_audiovisual_df_train %>%\n    select(Extr, Agr, Cons, Emot, Open)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:56.347092Z","iopub.execute_input":"2023-09-18T09:17:56.348460Z","iopub.status.idle":"2023-09-18T09:17:56.362186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we can calculate the RMSE with help of the `rmse()` function by pluggin in the observed and the predicted values for each of the 11 models (also per outcome if applicable). ","metadata":{}},{"cell_type":"code","source":"rmse_m1_extr <- rmse(unname(unlist(observed_train[, 1])), unname(unlist(pred_mlm_01_train[, 1])))\nrmse_m1_agr <- rmse(unname(unlist(observed_train[, 2])), unname(unlist(pred_mlm_01_train[, 2])))\nrmse_m1_cons <- rmse(unname(unlist(observed_train[, 3])), unname(unlist(pred_mlm_01_train[, 3])))\nrmse_m1_emot <- rmse(unname(unlist(observed_train[, 4])), unname(unlist(pred_mlm_01_train[, 4])))\nrmse_m1_open <- rmse(unname(unlist(observed_train[, 5])), unname(unlist(pred_mlm_01_train[, 5])))\n\nrmse_m2_extr <- rmse(unname(unlist(observed_train[, 1])), unname(unlist(pred_mlm_02_train[, 1])))\nrmse_m2_agr <- rmse(unname(unlist(observed_train[, 2])), unname(unlist(pred_mlm_02_train[, 2])))\nrmse_m2_cons <- rmse(unname(unlist(observed_train[, 3])), unname(unlist(pred_mlm_02_train[, 3])))\nrmse_m2_emot <- rmse(unname(unlist(observed_train[, 4])), unname(unlist(pred_mlm_02_train[, 4])))\nrmse_m2_open <- rmse(unname(unlist(observed_train[, 5])), unname(unlist(pred_mlm_02_train[, 5])))\n\nrmse_m3_extr <- rmse(unname(unlist(observed_train[, 1])), unname(unlist(pred_mlm_03_train[, 1])))\nrmse_m3_agr <- rmse(unname(unlist(observed_train[, 2])), unname(unlist(pred_mlm_03_train[, 2])))\nrmse_m3_cons <- rmse(unname(unlist(observed_train[, 3])), unname(unlist(pred_mlm_03_train[, 3])))\nrmse_m3_emot <- rmse(unname(unlist(observed_train[, 4])), unname(unlist(pred_mlm_03_train[, 4])))\nrmse_m3_open <- rmse(unname(unlist(observed_train[, 5])), unname(unlist(pred_mlm_03_train[, 5])))\n\nrmse_m4_extr <- rmse(unname(unlist(observed_train[, 1])), unname(unlist(pred_mlm_04_train[, 1])))\nrmse_m4_agr <- rmse(unname(unlist(observed_train[, 2])), unname(unlist(pred_mlm_04_train[, 2])))\nrmse_m4_cons <- rmse(unname(unlist(observed_train[, 3])), unname(unlist(pred_mlm_04_train[, 3])))\nrmse_m4_emot <- rmse(unname(unlist(observed_train[, 4])), unname(unlist(pred_mlm_04_train[, 4])))\nrmse_m4_open <- rmse(unname(unlist(observed_train[, 5])), unname(unlist(pred_mlm_04_train[, 5])))\n\nrmse_m5_extr <- rmse(unname(unlist(observed_train[, 1])), unname(unlist(pred_mlm_05_train[, 1])))\nrmse_m5_agr <- rmse(unname(unlist(observed_train[, 2])), unname(unlist(pred_mlm_05_train[, 2])))\nrmse_m5_cons <- rmse(unname(unlist(observed_train[, 3])), unname(unlist(pred_mlm_05_train[, 3])))\n\nrmse_m6_emot <- rmse(unname(unlist(observed_train[, 4])), unname(unlist(pred_mlm_06_train[, 1])))\nrmse_m6_open <- rmse(unname(unlist(observed_train[, 5])), unname(unlist(pred_mlm_06_train[, 2])))\n\nrmse_m10_extr <- rmse(unname(unlist(observed_train[, 1])), unname(unlist(pred_mlm_10_train[, 1])))\nrmse_m10_agr <- rmse(unname(unlist(observed_train[, 2])), unname(unlist(pred_mlm_10_train[, 2])))\nrmse_m10_cons <- rmse(unname(unlist(observed_train[, 3])), unname(unlist(pred_mlm_10_train[, 3])))\nrmse_m10_emot <- rmse(unname(unlist(observed_train[, 4])), unname(unlist(pred_mlm_10_train[, 4])))\nrmse_m10_open <- rmse(unname(unlist(observed_train[, 5])), unname(unlist(pred_mlm_10_train[, 5])))\n\nrmse_m11_extr <- rmse(unname(unlist(observed_train[, 1])), unname(unlist(pred_mlm_11_train[, 1])))\nrmse_m11_agr <- rmse(unname(unlist(observed_train[, 2])), unname(unlist(pred_mlm_11_train[, 2])))\nrmse_m11_cons <- rmse(unname(unlist(observed_train[, 3])), unname(unlist(pred_mlm_11_train[, 3])))\nrmse_m11_emot <- rmse(unname(unlist(observed_train[, 4])), unname(unlist(pred_mlm_11_train[, 4])))\nrmse_m11_open <- rmse(unname(unlist(observed_train[, 5])), unname(unlist(pred_mlm_11_train[, 5])))\n\nrmse_m1 <- rmse(unname(unlist(observed_train)), unname(unlist(pred_mlm_01_train)))\nrmse_m2 <- rmse(unname(unlist(observed_train)), unname(unlist(pred_mlm_02_train)))\nrmse_m3 <- rmse(unname(unlist(observed_train)), unname(unlist(pred_mlm_03_train)))\nrmse_m4 <- rmse(unname(unlist(observed_train)), unname(unlist(pred_mlm_04_train)))\nrmse_m5 <- rmse(unname(unlist(observed_train[,1:3])), unname(unlist(pred_mlm_05_train)))\nrmse_m6 <- rmse(unname(unlist(observed_train[,4:5])), unname(unlist(pred_mlm_06_train)))\nrmse_m7_cons <- rmse(observed_train[,3], pred_mlm_07_train)\nrmse_m8_agr <- rmse(observed_train[,2], pred_mlm_08_train)\nrmse_m9_emot <- rmse(observed_train[,4], pred_mlm_09_train)\nrmse_m10 <- rmse(unname(unlist(observed_train)), unname(unlist(pred_mlm_10_train)))\nrmse_m11 <- rmse(unname(unlist(observed_train)), unname(unlist(pred_mlm_11_train)))","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:17:58.754855Z","iopub.execute_input":"2023-09-18T09:17:58.757179Z","iopub.status.idle":"2023-09-18T09:17:58.839282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To have a better overview of all RMSE values, all RMSE values were put into one dataframe.","metadata":{}},{"cell_type":"code","source":"rmse_combined <- rbind(rmse_m1, rmse_m2, rmse_m3, rmse_m4, rmse_m5, rmse_m6, rmse_m10, rmse_m11,\n                       rmse_m1_extr, rmse_m1_agr, rmse_m1_cons, rmse_m1_emot, rmse_m1_open,\n                       rmse_m2_extr, rmse_m2_agr, rmse_m2_cons, rmse_m2_emot, rmse_m2_open,\n                       rmse_m3_extr, rmse_m3_agr, rmse_m3_cons, rmse_m3_emot, rmse_m3_open,\n                       rmse_m4_extr, rmse_m4_agr, rmse_m4_cons, rmse_m4_emot, rmse_m4_open,\n                       rmse_m5_extr, rmse_m5_agr, rmse_m5_cons,\n                       rmse_m6_emot, rmse_m6_open, \n                       rmse_m7_cons, \n                       rmse_m8_agr, \n                       rmse_m9_emot,\n                       rmse_m10_extr, rmse_m10_agr, rmse_m10_cons, rmse_m10_emot, rmse_m10_open,\n                       rmse_m11_extr, rmse_m11_agr, rmse_m11_cons, rmse_m11_emot, rmse_m11_open) %>%\n                       as.data.frame() %>% rownames_to_column(\"Model\") %>% \n                       rename(\"RMSE\" = \"V1\")\nrmse_combined","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:18:02.476822Z","iopub.execute_input":"2023-09-18T09:18:02.478259Z","iopub.status.idle":"2023-09-18T09:18:02.519589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 7 Model Selection\n\nWe selected the best model for each outcome (5) and the best model for all outcomes (1) based on the RMSE metric. The lower the RMSE value, the better the model fits the data. \n\nIn order to do that we made tables of the RMSE values per outcome and for the full models, in which we arranged the RMSE values to make it clear which model performs best. ","metadata":{}},{"cell_type":"code","source":"# Model per outcome \nrmse_combined %>% filter(grepl(\"open$\", Model)) %>% arrange(RMSE) \nrmse_combined %>% filter(grepl(\"cons$\", Model)) %>% arrange(RMSE) \nrmse_combined %>% filter(grepl(\"extr$\", Model)) %>% arrange(RMSE) \nrmse_combined %>% filter(grepl(\"agr$\", Model)) %>% arrange(RMSE)  \nrmse_combined %>% filter(grepl(\"emot$\", Model)) %>% arrange(RMSE)\n\n# Models containing all outcomes \nrmse_combined %>% filter(grepl(\"(1|2|3|4|10|11)$\", Model)) %>% arrange(RMSE) ","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:18:12.323581Z","iopub.execute_input":"2023-09-18T09:18:12.324862Z","iopub.status.idle":"2023-09-18T09:18:12.414398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As can be seen in the table, the RMSE values of the six models that contain all outcome variables (i.e., all personality traits) indicate that, overall, these models do not fit the data well, since the RMSE values are above 0.5 which indicates a bad model fit. Model 11, which included both audiovisual and text features as predictors, seems to have the best fit.\n\nOn the contrary, RMSE values of the model that only contained a selection of the outcome variables are below 0.5, indicating that these models do have acceptable fit. For each of the Big Five personality traits, model 11 outperforms the other models (though differences are slight). ","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 8 Writing Predictions to Files\n\n#### 8.1 Wide format\nIn order to display the predicitons of our best model, Model 11, we made the following wide dataframe.  ","metadata":{}},{"cell_type":"code","source":"testset_pred_11 = features_audiovisual_df_test %>% \n    mutate(\n        Extr = pred_mlm_11_test[,'Extr'], \n        Agr  = pred_mlm_11_test[,'Agr' ],\n        Cons = pred_mlm_11_test[,'Cons'],\n        Emot = pred_mlm_11_test[,'Emot'],\n        Open = pred_mlm_11_test[,'Open']\n    ) %>%\n    select(vlogId, Extr:Open)\n\ntestset_pred_11 %>% \n    head()","metadata":{"_uuid":"c3543421-d7bd-42ea-a880-23825de5f8bc","_cell_guid":"873a1bde-0f8e-446d-8153-5681e6d27134","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-18T09:18:16.612511Z","iopub.execute_input":"2023-09-18T09:18:16.613863Z","iopub.status.idle":"2023-09-18T09:18:16.645441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 8.2 Long dataframe with axis and predicition values\n\nWe transformed the wide format to a long format which contains `vlogI` (i.e. the ID of each vlogger), `axis` (i.e. one of the dimensions on the big5) and `predictions` (i.e. the predicted score on each big5 dimension)","metadata":{"_uuid":"2ef3a62f-62cf-42ca-9f50-c07a93d04ccf","_cell_guid":"4528893d-1930-4ccf-b4c0-51a0c773dae5","trusted":true}},{"cell_type":"code","source":"testset_pred_long_11 = testset_pred_11 %>% \n    pivot_longer(cols = Extr:Open, names_to = \"axis\", values_to = \"prediction\") %>%\n    arrange(`vlogId`,axis)\n\ntestset_pred_long_11 %>% \n    head()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:18:20.259020Z","iopub.execute_input":"2023-09-18T09:18:20.260209Z","iopub.status.idle":"2023-09-18T09:18:20.297845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 8.3 Final data frame\n\nFinally, we made a file containing a dataframe with two colums: the first column containing the vlogger id (`vlogId`) with big5 dimensions and the second column containing the expected value on the big5 dimensions (`Expected`).\n ","metadata":{}},{"cell_type":"code","source":"testset_pred_long_final_11 <- \n    testset_pred_long_11 %>%\n    unite(Id, `vlogId`, axis) %>%\n    rename(Expected = prediction)\n\nnrow(testset_pred_long_final_11) # n=400 is correct: 80 vloggers times 5 traits\n\ntestset_pred_long_final_11 %>% head()","metadata":{"_uuid":"4a729773-ad88-4830-9c24-f0893a61d381","_cell_guid":"84498e3c-77cc-4434-a91f-a099e72c93dd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-18T09:18:22.536042Z","iopub.execute_input":"2023-09-18T09:18:22.537349Z","iopub.status.idle":"2023-09-18T09:18:22.566781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 8.3 Writing output to .csv file\n\nThe resulting dataframe is written to a .csv file.\n","metadata":{}},{"cell_type":"code","source":"# Write to csv\nwrite_csv(testset_pred_long_final_11, file = \"predictions_model_11.csv\")\n\n# Checking directory\ndir()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:18:24.734902Z","iopub.execute_input":"2023-09-18T09:18:24.736205Z","iopub.status.idle":"2023-09-18T09:18:24.771291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 9 Visualizations\n\nTo visualize our results, we used a heatmap of the RMSE values per model. In order to visualize this, we created a dataframe with RMSE values and split those into variable (for each personality trait).","metadata":{}},{"cell_type":"code","source":"# dataframe containing the RMSE for each model (that contains all personality axes) on each personality trait\nrmse_data <- data.frame(\n  Variable = rep(c(\"Extroversion\", \"Agreeableness\", \"Conscientious\", \"Emotional stability\", \"Openness\"), each = 6),\n  Model = rep(c(\"Model1\", \"Model2\", \"Model3\", \"Model4\",\"Model10\", \"Model11\"), times = 5),\n  RMSE = c(\nrmse_m1_extr, rmse_m1_agr, rmse_m1_cons, rmse_m1_emot, rmse_m1_open,\nrmse_m2_extr, rmse_m2_agr, rmse_m2_cons, rmse_m2_emot, rmse_m2_open,\nrmse_m3_extr, rmse_m3_agr, rmse_m3_cons, rmse_m3_emot, rmse_m3_open,\nrmse_m4_extr, rmse_m4_agr, rmse_m4_cons, rmse_m4_emot, rmse_m4_open,\nrmse_m10_extr, rmse_m10_agr, rmse_m10_cons, rmse_m10_emot, rmse_m10_open,\nrmse_m11_extr, rmse_m11_agr, rmse_m11_cons, rmse_m11_emot, rmse_m11_open))\n\nmodel_order <- c(\"Model1\", \"Model2\", \"Model3\", \"Model4\", \"Model10\", \"Model11\")\n\nrmse_data$Model <- factor(rmse_data$Model, levels = model_order)\n\n# heatmap\nheatmap_plot <- ggplot(rmse_data, aes(x = Model, y = Variable, fill = RMSE)) +\n  geom_tile() +\n  labs(title = 'RMSE of Different \"Full\" Model Variables on the training data', fill = \"RMSE\") +\n  scale_fill_gradient(low = \"red\", high = \"white\") +\ngeom_text(aes(label = round(RMSE, 2))) +\n  theme_minimal()\nheatmap_plot\n\n# saving the plot\nggsave(\"heatmap.jpg\", plot = heatmap_plot)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:19:57.093364Z","iopub.execute_input":"2023-09-18T09:19:57.094667Z","iopub.status.idle":"2023-09-18T09:19:57.548210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Furthermore, we also visualized the RMSE values for the models containing all personality axes using a barplot. Again, we first created a dataframe with RMSE values for each of these models before visualizing it.","metadata":{}},{"cell_type":"code","source":"# dataframe containing the RMSE for each of these models \nrmse_data_2 <- data.frame(\n  Models = factor(c(\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\", \"Model 10\", \"Model 11\"),\n                  levels = c(\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\", \"Model 10\", \"Model 11\")),\n  y = c(rmse_m1, rmse_m2, rmse_m3, rmse_m4, rmse_m10, rmse_m11))\n\n# barplot\nbar_plot <- ggplot(rmse_data_2, aes(x = Models, y = y, fill = Models)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    title = 'RMSE of Different \"Full\" Models on the training data',\n    x = \"Models\",\n    y = \"RMSE\"\n  ) +\n  theme_minimal() +\ncoord_cartesian(ylim = c(0.7, 0.85)) +\ngeom_text(aes(label = round(y, 3)), vjust = -0.5, size = 3) \n\nbar_plot\n\n# saving the barplot\nggsave(\"barplot.jpg\", plot = bar_plot)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T09:20:11.330680Z","iopub.execute_input":"2023-09-18T09:20:11.332260Z","iopub.status.idle":"2023-09-18T09:20:12.141137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 10 Collaborators\n\n* Sophia Lorenz - Conceptual development, pre-processing, features, predictions, testing, model comparisions, visualizations, text & code style, final check-ups \n\n* Romy Leferink - Conceptual development, pre-processing, literature research, features, predictions, testing, model comparisions, visualizations, coding/editing, text & code style, final check-ups\n\n* Bence András Marosi - Conceptual development, pre-processing, features, predictions, testing, model comparisions, visualizations, coding/editing, final check-ups","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 11 References\n\nCasper van Tongeren, Enrico Erler, Raoul. (2022). Syllable counting model. Kaggle. https://kaggle.com/competitions/syllable-counting-model\n\ndan_vdmeer, Dave Leitritz, Raoul. (2023). BDA 2023 Profiling Personality. Kaggle. https://kaggle.com/competitions/bda-2023-profiling-personality\n\nFarnadi, G., Sitaraman, G., Rohani, M., Kosinski, M., Stillwell, D., Moens, M., Davalos, S., & De Cock, M. (2014). How are you doing? : emotions and personality in Facebook. EMPIRE 2014, 1181, 45–56.\n\nMaharani, W., & Effendy, V. (2022). Big five personality prediction based in Indonesian tweets using machine learning methods. International Journal of Power Electronics and Drive Systems, 12(2), 1973. https://doi.org/10.11591/ijece.v12i2.pp1973-1981\n\n@article{biel2013youtube,\n  title={The youtube lens: Crowdsourced personality impressions and audiovisual analysis of vlogs},\n  author={Biel, Joan-Isaac and Gatica-Perez, Daniel},\n  journal={Multimedia, IEEE Transactions on},\n  volume={15},\n  number={1},\n  pages={41--55},\n  year={2013},\n  publisher={IEEE}\n}\n\n@inproceedings{biel2013hi,\n  title={Hi YouTube!: personality impressions and verbal content in social video},\n  author={Biel, Joan-Isaac and Tsiminaki, Vagia and Dines, John and Gatica-Perez, Daniel},\n  booktitle={Proceedings of the 15th ACM on International conference on multimodal interaction},\n  pages={119--126},\n  year={2013},\n  organization={ACM}\n}\n\nRelated literature \n\nJ.-I. Biel and D. Gatica-Perez, “The YouTube Lens: Crowdsourced Personality Impressions\nand Audiovisual Analysis of Vlogs\" in IEEE Transactions on Multimedia , Vol. 15, No. 1,\npp. 41-55, Jan. 2013.\n\nJ.-I. Biel and D. Gatica-Perez. “VlogSense: Conversational Behavior and Social Attention\nin YouTube\" in ACM Transactions on Multimedia Computing, Communications, and Applications,\nSpecial Issue on Social Media, Oct 2011.\n\n J.-I. Biel, V. Vtsminaki, V., J. Dines and D. Gatica-Perez “Hi YouTube! What verbal content\nreveals in social video\" in Proceedings International Conference on Multimodal Interaction\n(ICMI) , Sydney, Dec. 2013.\n\nJ.-I. Biel, Teijeiro-Mosquera, L. and D. Gatica-Perez “FaceTube: Predicting Personality from\nFacial Expressions of Emotion in Online Conversational Video\" in Proceedings International\nConference on Multimodal Interaction (ICMI) , Santa Monica, Oct. 2012.\n\nJ.-I. Biel and D. Gatica-Perez “The Good, the Bad, and the Angry: Analyzing Crowdsourced\nImpressions of Vloggers\" in Proceedings of AAAI International Conference on Weblogs and\nSocial Media (ICWSM) , Dublin, June 2012\n\nJ-I. Biel, O. Aran, and D. Gatica-Perez, “You Are Known by How You Vlog: Personality\nImpressions and Nonverbal Behavior in YouTube” In Proc. AAAI Int. Conf. . on Weblogs\nand Social Media (ICWSM) , Barcelona, July 2011.\n\nJ.-I. Biel and D. Gatica-Perez, “Vlogcast Yourself: Nonverbal Behavior and Attention in\nSocial","metadata":{}}]}